{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"\n# Import libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy.random as np\nimport sys\nimport matplotlib \nimport numpy as np\nimport seaborn as sns\nfrom subprocess import check_output\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Location of file\nLocation = '../input/acs2015_census_tract_data.csv'\n\ndf = pd.read_csv(Location)\n\ndf.info()","execution_count":27,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"12dda5e1e0dc23cb231fde919c0a583cfed3673a"},"cell_type":"code","source":"#In case we wanted to just see the data types of each column\n#df.dtypes;","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"984d9108707c89f1b7974f26a4fad5290f6b23dc"},"cell_type":"code","source":"#Drop unnecessary columns and Data that has nan values\ndf = df.drop(['CensusTract','County'], 1)\ndf=df.dropna()\ndf = df.reset_index(drop = True)\ndf.shape","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"054f09663d6e35745fae626a4510d695629200b9"},"cell_type":"code","source":"df.head()","execution_count":29,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7c055324d8fe40097ea944298a1951090c14bc5a"},"cell_type":"code","source":"#Convert percent of each race into total number of people with this ethnicity for each county\n#Also find the total number of people that are self-employed, unemployed, etc... for each county\n\nheadnames = list(df)\nX=headnames[4:10]\nX.extend(headnames[len(headnames)-5:len(headnames)])\n\nfor i in X:\n    df[i] = df['TotalPop'] * df[i]/100   \n\n    #We won't be doing further data cleaning on our data in this tutorial.\n","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8931b89f8dcb47bd1eaf5fd80dff31c8acbb4ea"},"cell_type":"code","source":"#Just to double check our X here\n\nX","execution_count":8,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"2711462e15d27c5686f50342cca4c00c142cc66d"},"cell_type":"code","source":"#Group Data By State\n\ndf = df.groupby('State', as_index=False).sum()\n\n#creates new column of df with the fraction of each gender in each state \ndf['M_share'] = df.Men/df.TotalPop \ndf['F_share'] = df.Women/df.TotalPop \n\n#creates new column of df with the fraction of unemployed people in each state\ndf['Unemployment_Rate'] = df.Unemployment/df.TotalPop \n\n#creates now column of df with the fraction of each race in each state \n\ndf['White Fraction'] = df.White/df.TotalPop\ndf['Black Fraction'] = df.Black/df.TotalPop\n\ndf['Asian Fraction']=df.Asian/df.TotalPop\ndf['Hispanic Fraction']=df.Hispanic/df.TotalPop\n\ndf['Native Fraction']=df.Native/df.TotalPop\n\ndf['Pacific Fraction']=df.Asian/df.TotalPop\n\n#Since I am interested in just the 50 US states and DC, I eliminate Puerto Rico from the dataset\ndf=df[~(df['State']=='Puerto Rico')]\n\n\ndf = df.reset_index(drop = True)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec16489b41e44793ca2014262506273ad6133d5e"},"cell_type":"code","source":"#Let's see what we are working with now\n\ndf.head()","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"361d16eda90ca600170df0c1b2c3cef615072f1b"},"cell_type":"code","source":"#Let's look at the top and bottom 10 states for the fraction of unemployment\n\n#For those that have latex, this is a nice way to print out labels\n#plt.rc('text', usetex=True)\n\nplt.rc('font', family='serif')\nplt.rcParams.update({'font.size': 14})\n\nsorted_df = df.sort_values(['Unemployment_Rate'], ascending = [True])\n\nplt.figure(figsize = (10,10))\n\nplt.subplot(2,1,1)\nplt.barh(range(10),sorted_df.tail(10).Unemployment_Rate)\nplt.yticks(range(10),sorted_df.tail(10).State, fontsize = 10)\nplt.plot([1,1],[0,10], '--',color = 'r')\nplt.title('Top 10 Unemployment Rates By State 2011-2015')\nplt.xlim([0,0.11])\n\n\nplt.subplot(2,1,2)\nplt.barh(range(10),sorted_df.head(10).Unemployment_Rate)\nplt.yticks(range(10),sorted_df.head(10).State, fontsize = 10)\nplt.plot([1,1],[0,10], '--',color = 'r')\nplt.title('Lowest 10 Unemployment Rates By State 2011-2015')\nplt.xlim([0,0.11])","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"864a9225519160d36becc8e576c811e47e2a4fbe"},"cell_type":"markdown","source":"For those that have access to plotly, you can use the code below to plot the unemployment rates per each state on as US Map.\n\n"},{"metadata":{"_kg_hide-output":true,"collapsed":true,"trusted":true,"_uuid":"eed562eca96c77d73b486e94786d84b25f331d1d"},"cell_type":"code","source":"!pip install plotly\nimport plotly.plotly as py\n\n\n#df2 has all the state abbreviations that we need for the color map\ndf2 = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv')\ndf=df[~(df['State']=='District of Columbia')]\n\nscl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n\n\ndata = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = df2['code'],\n        z = df['Unemployment_Rate'].astype(float),\n        locationmode = 'USA-states',\n        text = df2['code'],\n        marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Unemployment Rate\")\n        ) ]\n\nlayout = dict(\n          geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\npy.iplot( fig, filename ='Unemployment Rate' )\n\n#Pretty Plot will show!\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b11c2795e9921542de373b8ebbf234aec426b02"},"cell_type":"markdown","source":"Throughout Financial Crisis and the Great Recession (2007 - 2009), millions of jobs were lost in the US alone, and the mean household wealth significantly dropped.  According to [Pew Research](http://www.pewsocialtrends.org/2011/07/26/wealth-gaps-rise-to-record-highs-between-whites-blacks-hispanics/), there was a much more significant drop in the median net household worth for African Americans and Hispanics than Whites in the US during the recession.  Sadly, even years after the recession, the unemployment rate for African Americans is approximately double the unemployment rate for Whites (As illustrated in the data from [Pew Research](http://www.pewresearch.org/fact-tank/2013/08/21/through-good-times-and-bad-black-unemployment-is-consistently-double-that-of-whites/)).\n\n\nThe data used in this study is from the 2015 American Community 5 year Survey (2011 - 2015).  We can use this data to explore the evolution of post-recession unemployment in the US.  I am particularly curious to see if race has an correlation to unemployment (per state) in the US, and if so, how strong is this correlation?\n\nLet's start by looking at a heat map of the correlations between the fraction of each race to the unemployment rate in each state.\n"},{"metadata":{"trusted":true,"_uuid":"d16e696e97196ed7d7779afdad5c931482e18826"},"cell_type":"code","source":"plt.figure(figsize = (10,10))\nf=df[df.columns[37:]].corr()\nax=sns.heatmap(f, annot=True)","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"99d7b60add3322317fe101c5156559d15cf72d6c"},"cell_type":"markdown","source":"As we can see from this plot, there is a strong negative correlation between the fraction of white people in a state and the unemployment rate.  Conversely, there is a strong positive correlation between the fraction of Hispanic and African Americans in a state and the unemployment rate.  For Asians and Pacific Ocean, there is only a small correlation.  For Native Americans, there is a moderatel sized negative correlation.  Although this does not make sense (See for example [US News article](http://www.usnews.com/news/articles/2014/11/27/native-americans-left-behind-in-the-economic-recovery) or [Economic Policy Institute article](http://www.epi.org/publication/high-unemployment-means-native-americans/)), the key here is that this data only gives the net unemployment rate and the fraction of each ethnicity in for a state.  This means that a state with reasonably low unemployment could actually have a relatively high amount of unemployment for a particular ethnic group.   \n\nBelow I go through regression analysis on the data.  However, the most important thing to point out is that regression is really describing the demographics of unemployment, not the relative unemployment for each ethnic group.  For the latter, we would need the unemployment rate for each ethnic group in each state.  Nevertheless, such an analysis can tell us whether certain ethnic groups tend to reside in states with high unemployment, which would provide motivation to do a more extensive study of the correlation of race and unemployment rate.  \n"},{"metadata":{"trusted":true,"_uuid":"9f708b1253967c556c5fe4cbf293fe6f1cb75168"},"cell_type":"code","source":"\nnew_df= pd.DataFrame()\n\nnew_df=df[df.columns[38:]]\n\n\nmodel = LinearRegression()\nX = new_df\n\n\n#StandardScalar() standardizes features by removing the mean and scaling to unit variance\nX_std = StandardScaler().fit_transform(X)\n#X_std=X\ny = df['Unemployment_Rate']\n\nX_train, X_test, y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=42)\n\nmodel.fit(X_train,y_train)\n\nplt.figure(figsize = (9,8))\nplt.barh(range(X.shape[1]),model.coef_)\nplt.xlabel('Coefficient')\n\nplt.yticks(range(X.shape[1]),list(new_df), fontsize = 12)\nplt.title('Regression Coefficients')\n\nplt.show()\n\nprint('R^2 on training...',model.score(X_train,y_train))\nprint('R^2 on test...',model.score(X_test,y_test))\n\nprint('Model Coefficients',model.coef_)\nprint('Model Intercept',model.intercept_)","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b6207468f946aaf4cd548a97aad27d642c305e6"},"cell_type":"code","source":"#Just to Doublecheck the Machine Learning Score, which we see doesn't have as good as R^2 score as the Machine Learnning One\n\nimport statsmodels.api as sm # import statsmodels \n\nX = X_std## X usually means our input variables (or independent variables)\n#X=new_df\ny = df[\"Unemployment_Rate\"] ## Y usually means our output/dependent variable\nX = sm.add_constant(X) ## let's add an intercept (beta_0) to our model\n\n# Note the difference in argument order\nmodel = sm.OLS(y, X).fit() ## sm.OLS(output, input)\npredictions = model.predict(X)\n\n# Print out the statistics\nmodel.summary()\n","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"b0074eedbb88f68fea3cb9e06797c2023104a4e9"},"cell_type":"markdown","source":"Our regression analysis shows a moderate effect (0.5 < R^2 < 0.75) of race and the unemployment rate in each state.  The positive coefficients for African Americans and Hispanics reflect that these races tend to live in states with a high unemployment rate.  Conversely, the substantial negative coefficient for Whites reflects that Whites predominently reside in states with lower unemployment rates.  \n"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"6e0a1526c6ea65c6b69ba845dffb49e48110726f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}